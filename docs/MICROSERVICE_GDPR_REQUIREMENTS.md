# üîí Microservice GDPR Requirements - Technical Implementation

**Scenario:** After development, the microservice becomes IPSI's internal service  
**Question:** What must the microservice itself have to be GDPR compliant?  
**Date:** November 24, 2025

---

## üéØ Understanding the Final State

### **Current Situation:**
```
Development Phase:
‚îú‚îÄ You build the microservice
‚îú‚îÄ Use anonymized data for testing
‚îú‚îÄ No real personal data involved
‚îî‚îÄ No GDPR issues during dev ‚úÖ

After You Finish:
‚îú‚îÄ Microservice becomes IPSI's service
‚îú‚îÄ Deployed on IPSI infrastructure
‚îú‚îÄ Part of IPSI platform (not third party)
‚îú‚îÄ IPSI operates it
‚îî‚îÄ IPSI is responsible for GDPR
```

### **Key Insight:**
Once deployed, it's **IPSI's internal service**, not a third-party service. The GDPR requirements are about what **features** the microservice must have, not about legal agreements between you and IPSI.

---

## ‚úÖ **GDPR Features Your Microservice MUST Have**

### **1. Right to Erasure (Delete) - CRITICAL** üî¥

**GDPR Article 17 - Right to be Forgotten**

**The Problem:**
```python
# Current: No way to delete student data
# If student requests deletion, IPSI must comply within 30 days
```

**Required Feature:**
```python
# DELETE endpoint to remove ALL student data
DELETE /api/v1/students/{external_student_id}

What it must delete:
‚îú‚îÄ Student profile from PostgreSQL ‚úì
‚îú‚îÄ Student embeddings from Qdrant ‚úì
‚îú‚îÄ All match history for that student ‚úì
‚îú‚îÄ All application records ‚úì
‚îî‚îÄ Any cached data ‚úì
```

**Implementation:**
```python
@router.delete("/students/{external_student_id}")
async def delete_student_data(
    external_student_id: str,
    db: Session = Depends(get_database)
):
    """
    Delete all student data (GDPR Article 17 - Right to Erasure).
    
    This is CRITICAL for GDPR compliance!
    """
    student = db.query(StudentProfile).filter(
        StudentProfile.external_student_id == external_student_id
    ).first()
    
    if not student:
        return {"status": "not_found"}
    
    # 1. Delete from Qdrant (vector embeddings)
    qdrant_service = get_qdrant_service()
    qdrant_service.delete_points(
        collection_name="students_global",
        points=[str(student.qdrant_point_id)]
    )
    
    # 2. Delete related records (CASCADE)
    # Delete applications
    db.query(Application).filter(
        Application.student_profile_id == student.id
    ).delete()
    
    # Delete match history
    db.query(MatchHistory).filter(
        MatchHistory.student_profile_id == student.id
    ).delete()
    
    # 3. Delete student profile
    db.delete(student)
    db.commit()
    
    logger.info("student.deleted", 
               student_id=external_student_id,
               reason="gdpr_right_to_erasure")
    
    return {
        "status": "deleted",
        "student_id": external_student_id,
        "deleted_at": datetime.utcnow().isoformat()
    }
```

**Why Critical:**
- ‚úÖ **Required by law** (GDPR Article 17)
- ‚úÖ Students can request deletion anytime
- ‚úÖ IPSI must comply within 30 days
- ‚úÖ Fines up to ‚Ç¨20 million or 4% revenue if missing

**Time to implement:** 2-3 hours

---

### **2. Data Export (Portability) - REQUIRED** üü†

**GDPR Article 20 - Right to Data Portability**

**The Problem:**
```python
# Current: No way to export student data
# Students have right to get their data in machine-readable format
```

**Required Feature:**
```python
# GET endpoint to export student data
GET /api/v1/students/{external_student_id}/export?format=json
```

**Implementation:**
```python
@router.get("/students/{external_student_id}/export")
async def export_student_data(
    external_student_id: str,
    format: str = "json",  # json, csv
    db: Session = Depends(get_database)
):
    """
    Export student data (GDPR Article 20 - Right to Data Portability).
    
    Returns all data stored about the student.
    """
    student = db.query(StudentProfile).filter(
        StudentProfile.external_student_id == external_student_id
    ).first()
    
    if not student:
        raise NotFoundException("Student", external_student_id)
    
    # Collect all data
    export_data = {
        "student_id": student.external_student_id,
        "profile_summary": student.profile_summary,
        "profile_data": student.structured_data,
        "embedding_version": student.embedding_version,
        "created_at": student.created_at.isoformat(),
        "updated_at": student.updated_at.isoformat(),
        
        # Applications
        "applications": [
            {
                "company_name": app.company.name,
                "job_title": app.job_posting.title if app.job_posting else None,
                "status": app.status,
                "application_date": app.application_date.isoformat()
            }
            for app in student.applications
        ],
        
        # Match history (last 90 days only)
        "match_history": [
            {
                "job_title": match.job_posting.title,
                "company_name": match.job_posting.company.name,
                "similarity_score": match.similarity_score,
                "rank": match.rank_position,
                "matched_at": match.created_at.isoformat()
            }
            for match in student.match_history[-100:]
        ]
    }
    
    if format == "json":
        return JSONResponse(content=export_data)
    elif format == "csv":
        # Convert to CSV
        csv_content = convert_to_csv(export_data)
        return Response(
            content=csv_content,
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=student_data_{external_student_id}.csv"
            }
        )
```

**Why Required:**
- ‚úÖ Students have right to their data
- ‚úÖ Must be machine-readable (JSON/CSV)
- ‚úÖ Must include all stored data
- ‚úÖ Free of charge, within 30 days

**Time to implement:** 2-3 hours

---

### **3. Data Retention & Auto-Cleanup - CRITICAL** üî¥

**GDPR Article 5(1)(e) - Storage Limitation**

**The Problem:**
```python
# Current: Data kept forever
# match_history grows indefinitely
# Inactive profiles never deleted
```

**Required Feature:**
Automatic cleanup of old data

**Implementation:**

```python
# scripts/cleanup_gdpr.py (NEW FILE)

from datetime import datetime, timedelta
from sqlalchemy.orm import Session
from app.models.database import MatchHistory, StudentProfile, JobPosting
from app.core.qdrant_client import get_qdrant_service

def cleanup_old_match_history(db: Session, retention_days: int = 90):
    """
    Delete match history older than retention period.
    
    GDPR: Data should not be kept longer than necessary.
    Match history is for analytics - 90 days is reasonable.
    """
    cutoff_date = datetime.utcnow() - timedelta(days=retention_days)
    
    deleted_count = db.query(MatchHistory).filter(
        MatchHistory.created_at < cutoff_date
    ).delete()
    
    db.commit()
    
    logger.info("cleanup.match_history", 
               deleted_count=deleted_count,
               cutoff_date=cutoff_date.isoformat())
    
    return deleted_count


def cleanup_inactive_students(db: Session, inactive_days: int = 365):
    """
    Delete student profiles not updated in X days.
    
    GDPR: Inactive accounts should be removed after reasonable period.
    """
    cutoff_date = datetime.utcnow() - timedelta(days=inactive_days)
    qdrant = get_qdrant_service()
    
    # Find inactive students
    inactive_students = db.query(StudentProfile).filter(
        StudentProfile.updated_at < cutoff_date
    ).all()
    
    deleted_count = 0
    for student in inactive_students:
        # Delete from Qdrant
        try:
            qdrant.delete_points(
                collection_name="students_global",
                points=[str(student.qdrant_point_id)]
            )
        except Exception as e:
            logger.error("cleanup.qdrant_delete_failed", 
                        student_id=student.external_student_id,
                        error=str(e))
        
        # Delete related data
        db.query(Application).filter(
            Application.student_profile_id == student.id
        ).delete()
        
        db.query(MatchHistory).filter(
            MatchHistory.student_profile_id == student.id
        ).delete()
        
        # Delete student
        db.delete(student)
        deleted_count += 1
    
    db.commit()
    
    logger.info("cleanup.inactive_students",
               deleted_count=deleted_count,
               cutoff_date=cutoff_date.isoformat())
    
    return deleted_count


def cleanup_old_jobs(db: Session, retention_days: int = 180):
    """
    Delete old job postings (after job is closed/filled).
    
    Keep for 180 days after creation for analytics.
    """
    cutoff_date = datetime.utcnow() - timedelta(days=retention_days)
    qdrant = get_qdrant_service()
    
    old_jobs = db.query(JobPosting).filter(
        JobPosting.created_at < cutoff_date
    ).all()
    
    deleted_count = 0
    for job in old_jobs:
        # Delete from Qdrant
        try:
            qdrant.delete_points(
                collection_name="jobs_global",
                points=[str(job.qdrant_point_id)]
            )
        except Exception as e:
            logger.error("cleanup.qdrant_delete_failed",
                        job_id=job.external_job_id,
                        error=str(e))
        
        # Delete related data
        db.query(Application).filter(
            Application.job_posting_id == job.id
        ).delete()
        
        db.query(MatchHistory).filter(
            MatchHistory.job_posting_id == job.id
        ).delete()
        
        # Delete job
        db.delete(job)
        deleted_count += 1
    
    db.commit()
    
    logger.info("cleanup.old_jobs",
               deleted_count=deleted_count,
               cutoff_date=cutoff_date.isoformat())
    
    return deleted_count


if __name__ == "__main__":
    from app.db.session import SessionLocal
    
    db = SessionLocal()
    
    try:
        print("Starting GDPR cleanup...")
        
        # Cleanup match history older than 90 days
        match_count = cleanup_old_match_history(db, retention_days=90)
        print(f"Deleted {match_count} old match history records")
        
        # Cleanup inactive students (1 year)
        student_count = cleanup_inactive_students(db, inactive_days=365)
        print(f"Deleted {student_count} inactive student profiles")
        
        # Cleanup old jobs (6 months)
        job_count = cleanup_old_jobs(db, retention_days=180)
        print(f"Deleted {job_count} old job postings")
        
        print("GDPR cleanup completed successfully!")
        
    except Exception as e:
        print(f"Cleanup failed: {e}")
        db.rollback()
    finally:
        db.close()
```

**Schedule as Cron Job:**
```bash
# Add to crontab (run daily at 2 AM)
0 2 * * * cd /app && python scripts/cleanup_gdpr.py >> /var/log/gdpr_cleanup.log 2>&1
```

**Or via Docker:**
```yaml
# docker-compose.yml
services:
  gdpr-cleanup:
    image: ipsi-ai-matching:latest
    command: python scripts/cleanup_gdpr.py
    environment:
      - DATABASE_URL=${DATABASE_URL}
    deploy:
      restart_policy:
        condition: none
    # Run via cron on host or Kubernetes CronJob
```

**Retention Periods (Recommended):**
- **match_history:** 90 days (analytics)
- **inactive students:** 12 months (no updates)
- **old jobs:** 6 months (after creation)
- **applications:** 24 months (recruitment records)

**Why Critical:**
- ‚úÖ **Required by GDPR** (storage limitation)
- ‚úÖ Data should not be kept longer than necessary
- ‚úÖ Reduces risk if breached
- ‚úÖ Shows good data governance

**Time to implement:** 3-4 hours

---

### **4. No Personal Data in Logs - REQUIRED** üü†

**GDPR Article 5(1)(f) - Security**

**The Problem:**
```python
# Risk: Accidentally logging personal data
logger.info("processing_student", name="Max Mustermann")  # ‚ùå BAD!
```

**Required Feature:**
Logging that ONLY logs anonymized IDs and technical data

**Current Status:**
‚úÖ **Already compliant!** Your logs look good:

```python
# ‚úÖ GOOD - Current implementation
logger.info("matching.students_for_job.start", 
           job_id=external_job_id,        # Anonymized ‚úì
           top_k=top_k,                    # Technical ‚úì
           min_score=min_similarity_score) # Technical ‚úì

logger.info("matching.generating_ai_insights",
           student_id=external_student_id,  # Anonymized ‚úì
           rank=rank,                        # Technical ‚úì
           score=result["score"])            # Technical ‚úì
```

**What to Avoid:**
```python
# ‚ùå NEVER log these
logger.info("student_name", name=student.name)  # Personal data!
logger.info("email", email=student.email)      # Personal data!
logger.info("skills", skills=student.skills)    # Could identify person
logger.info("cv_text", text=cv_text)           # Personal data!
```

**Validation Rule:**
```python
# Add logging validator
class GDPRLogFilter(logging.Filter):
    """Filter to prevent logging personal data."""
    
    FORBIDDEN_FIELDS = [
        'name', 'email', 'phone', 'address',
        'firstname', 'lastname', 'fullname',
        'birth', 'age', 'ssn', 'passport'
    ]
    
    def filter(self, record):
        # Check if log contains forbidden fields
        if hasattr(record, 'msg'):
            msg_lower = str(record.msg).lower()
            for field in self.FORBIDDEN_FIELDS:
                if field in msg_lower:
                    logger.error("gdpr.logging_violation",
                                forbidden_field=field)
                    return False
        return True

# Add to logging config
logging.getLogger().addFilter(GDPRLogFilter())
```

**Time to implement:** 1 hour (validation)

---

### **5. Opt-Out Mechanism - REQUIRED** üü°

**GDPR Article 21 - Right to Object**

**The Problem:**
```python
# Students should be able to opt-out of AI matching
# Even if they use IPSI platform
```

**Required Feature:**
```python
# Opt-out flag in database
class StudentProfile(Base):
    __tablename__ = "student_profiles"
    
    # ... existing fields ...
    
    # Add opt-out field
    ai_matching_opt_out = Column(Boolean, default=False)
    opt_out_date = Column(DateTime, nullable=True)
```

**API Endpoint:**
```python
@router.post("/students/{external_student_id}/opt-out")
async def opt_out_ai_matching(
    external_student_id: str,
    db: Session = Depends(get_database)
):
    """
    Student opts out of AI matching (GDPR Article 21).
    
    They can still use IPSI, but won't appear in AI matches.
    """
    student = db.query(StudentProfile).filter(
        StudentProfile.external_student_id == external_student_id
    ).first()
    
    if not student:
        raise NotFoundException("Student", external_student_id)
    
    student.ai_matching_opt_out = True
    student.opt_out_date = datetime.utcnow()
    db.commit()
    
    logger.info("student.opted_out",
               student_id=external_student_id)
    
    return {
        "status": "opted_out",
        "message": "You will no longer appear in AI matching results"
    }

@router.post("/students/{external_student_id}/opt-in")
async def opt_in_ai_matching(
    external_student_id: str,
    db: Session = Depends(get_database)
):
    """Student opts back in to AI matching."""
    student = db.query(StudentProfile).filter(
        StudentProfile.external_student_id == external_student_id
    ).first()
    
    if not student:
        raise NotFoundException("Student", external_student_id)
    
    student.ai_matching_opt_out = False
    student.opt_out_date = None
    db.commit()
    
    return {"status": "opted_in"}
```

**Update Matching to Respect Opt-Out:**
```python
# app/services/matching_service.py

async def find_students_for_job(...):
    # ... existing code ...
    
    # Filter out opted-out students
    students = db.query(StudentProfile).filter(
        StudentProfile.external_student_id.in_(external_student_ids),
        StudentProfile.ai_matching_opt_out == False  # ‚Üê Respect opt-out
    ).all()
    
    # Continue with matching...
```

**Time to implement:** 2-3 hours

---

### **6. Audit Logging - RECOMMENDED** üü°

**GDPR Article 5(2) - Accountability**

**The Problem:**
```python
# Need to prove GDPR compliance
# Need audit trail for data protection authority
```

**Required Feature:**
Log all data access/modifications

**Implementation:**
```python
# Already have match_history table ‚úì
# Add more detailed logging

class AuditLog(Base):
    """Audit log for GDPR compliance."""
    
    __tablename__ = "audit_logs"
    
    id = Column(UUID, primary_key=True, default=uuid.uuid4)
    event_type = Column(String(50))  # "data_access", "data_delete", "data_export"
    entity_type = Column(String(50))  # "student", "job", "company"
    entity_id = Column(String(255))   # external_student_id, external_job_id
    action = Column(String(50))       # "read", "update", "delete", "export"
    requested_by = Column(String(255))  # Who requested (anonymized)
    ip_address = Column(String(45))     # For security
    user_agent = Column(String(255))    # For security
    success = Column(Boolean)           # Did it succeed?
    details = Column(JSON)              # Additional info
    created_at = Column(DateTime, default=datetime.utcnow)

# Log important events
async def log_audit_event(
    db: Session,
    event_type: str,
    entity_type: str,
    entity_id: str,
    action: str,
    requested_by: str,
    success: bool,
    details: dict = None
):
    """Log audit event for GDPR compliance."""
    audit_log = AuditLog(
        event_type=event_type,
        entity_type=entity_type,
        entity_id=entity_id,
        action=action,
        requested_by=requested_by,
        success=success,
        details=details
    )
    db.add(audit_log)
    db.commit()

# Use in endpoints
@router.delete("/students/{external_student_id}")
async def delete_student_data(...):
    # ... delete logic ...
    
    # Log for audit
    await log_audit_event(
        db=db,
        event_type="gdpr_erasure",
        entity_type="student",
        entity_id=external_student_id,
        action="delete",
        requested_by=current_user.get("sub", "unknown"),
        success=True,
        details={"reason": "right_to_erasure"}
    )
```

**Time to implement:** 3-4 hours

---

### **7. No Sensitive Data Processing - VALIDATION** üü†

**GDPR Article 9 - Special Categories**

**The Problem:**
```python
# Risk: Accidentally receiving sensitive data
# Race, religion, health, biometric, etc.
```

**Required Feature:**
Input validation to reject sensitive data

```python
# app/models/schemas.py - Add validation

SENSITIVE_KEYWORDS = [
    # Race/ethnicity
    'race', 'ethnicity', 'ethnic', 'nationality',
    # Religion
    'religion', 'religious', 'christian', 'muslim', 'jewish', 'hindu',
    # Health
    'health', 'medical', 'disability', 'disease', 'condition',
    # Political
    'political', 'party', 'conservative', 'liberal',
    # Sexual orientation
    'sexual', 'orientation', 'gay', 'lesbian', 'transgender',
    # Biometric
    'fingerprint', 'facial', 'biometric', 'iris', 'retina',
    # Genetic
    'genetic', 'dna', 'gene'
]

@validator('*')
def no_sensitive_data(cls, v, field):
    """Reject input containing sensitive data markers."""
    if isinstance(v, str):
        v_lower = v.lower()
        for keyword in SENSITIVE_KEYWORDS:
            if keyword in v_lower:
                raise ValueError(
                    f"Sensitive data detected in field '{field.name}'. "
                    f"Cannot process special categories under GDPR Article 9."
                )
    return v
```

**Time to implement:** 1-2 hours

---

## üìã **Required Features Summary**

### **CRITICAL (Must Have Before Production):**

| Feature | GDPR Article | Status | Time | Priority |
|---------|-------------|--------|------|----------|
| **Delete Endpoint** | Article 17 | ‚ùå Missing | 2-3h | üî¥ CRITICAL |
| **Export Endpoint** | Article 20 | ‚ùå Missing | 2-3h | üü† HIGH |
| **Auto-Cleanup** | Article 5(1)(e) | ‚ùå Missing | 3-4h | üî¥ CRITICAL |
| **Opt-Out** | Article 21 | ‚ùå Missing | 2-3h | üü° MEDIUM |
| **Clean Logging** | Article 5(1)(f) | ‚úÖ Done | 0h | ‚úÖ DONE |
| **Audit Logging** | Article 5(2) | ‚ö†Ô∏è Partial | 3-4h | üü° MEDIUM |
| **Sensitive Data Block** | Article 9 | ‚ùå Missing | 1-2h | üü† HIGH |

**Total Implementation Time: 15-20 hours**

---

### **Implementation Checklist:**

**Week 1 (Critical Features):**
- [ ] Implement DELETE endpoint (Article 17)
- [ ] Implement EXPORT endpoint (Article 20)
- [ ] Create auto-cleanup script (Article 5)
- [ ] Schedule cleanup cron job
- [ ] Test deletion from both PostgreSQL and Qdrant

**Week 2 (Important Features):**
- [ ] Add opt-out mechanism (Article 21)
- [ ] Update matching to respect opt-out
- [ ] Add sensitive data validation
- [ ] Implement audit logging
- [ ] Test all GDPR features

**Week 3 (Documentation & Testing):**
- [ ] Document data retention policy
- [ ] Create GDPR compliance guide for IPSI
- [ ] Test all endpoints
- [ ] Security audit
- [ ] Ready for deployment

---

## üéØ **What DOESN'T Need to Be in the Microservice**

### **IPSI's Responsibility (Not in Your Code):**

**1. Consent Collection**
- ‚ùå NOT your microservice's job
- ‚úÖ IPSI's web interface handles this
- ‚úÖ Your service just receives anonymized data

**2. Privacy Policy**
- ‚ùå NOT your documentation
- ‚úÖ IPSI's legal document
- ‚úÖ Should mention AI matching

**3. User Authentication**
- ‚ùå NOT your auth system
- ‚úÖ IPSI handles user login
- ‚úÖ You use JWT tokens IPSI provides

**4. Direct User Interface**
- ‚ùå NO student-facing UI in microservice
- ‚úÖ IPSI's web app shows results
- ‚úÖ Your service is backend only

---

## üìÑ **Documentation You Should Provide**

### **For IPSI to Operate the Service:**

**1. Data Retention Policy Document:**
```markdown
# Data Retention Policy - IPSI AI Matching

## Retention Periods:
- Match history: 90 days
- Inactive student profiles: 12 months (no updates)
- Old job postings: 6 months
- Application records: 24 months

## Automated Cleanup:
- Daily cron job at 2 AM
- Logs cleanup actions
- Can be manually triggered if needed

## Manual Deletion:
- Students can request deletion anytime
- IPSI must process within 30 days
- Call: DELETE /api/v1/students/{id}
```

**2. GDPR Compliance Guide:**
```markdown
# GDPR Compliance Guide for IPSI

## Student Rights:

### Right to Erasure (Article 17):
When student requests deletion:
1. Call: DELETE /api/v1/students/{external_student_id}
2. Service deletes all data (PostgreSQL + Qdrant)
3. Confirm deletion to student within 30 days

### Right to Data Portability (Article 20):
When student requests data export:
1. Call: GET /api/v1/students/{id}/export?format=json
2. Send file to student within 30 days
3. No charge

### Right to Object (Article 21):
When student opts out:
1. Call: POST /api/v1/students/{id}/opt-out
2. Student won't appear in matches
3. Can opt back in anytime

## Data Processing:
- Only anonymized data stored
- No names, emails, addresses
- Auto-cleanup after retention period
- Encrypted at rest and in transit
```

**3. Operations Manual:**
```markdown
# Operations Manual - IPSI AI Matching Service

## Daily Operations:
- Automated cleanup runs at 2 AM
- Check logs: /var/log/gdpr_cleanup.log
- Monitor Qdrant storage

## Student Requests:
- Deletion: Use DELETE endpoint
- Export: Use GET /export endpoint
- Opt-out: Use POST /opt-out endpoint

## Incident Response:
- Data breach: Notify within 72 hours
- Contact data protection officer
- Check audit logs for affected users

## Maintenance:
- Weekly: Review cleanup logs
- Monthly: Qdrant optimization
- Quarterly: Security audit
```

---

## üöÄ **Implementation Priority**

### **Before Production Launch (MUST HAVE):**

**Priority 1: Data Deletion** (3-4 hours)
```
Why: Legal requirement, no workaround
Risk: Cannot comply with erasure requests
Impact: Could result in fines
```

**Priority 2: Auto-Cleanup** (3-4 hours)
```
Why: Storage limitation principle
Risk: Data kept longer than necessary
Impact: GDPR violation, increased breach risk
```

**Priority 3: Data Export** (2-3 hours)
```
Why: Right to portability
Risk: Cannot provide student data
Impact: GDPR violation
```

**Total Critical: 8-11 hours**

---

### **Shortly After Launch (IMPORTANT):**

**Priority 4: Opt-Out** (2-3 hours)
```
Why: Right to object
Risk: Cannot stop processing
Impact: Student complaints
```

**Priority 5: Sensitive Data Block** (1-2 hours)
```
Why: Prevent Article 9 violations
Risk: Accidentally process sensitive data
Impact: Severe GDPR violation
```

**Priority 6: Audit Logging** (3-4 hours)
```
Why: Accountability principle
Risk: Cannot prove compliance
Impact: Regulatory audit issues
```

**Total Important: 6-9 hours**

---

## ‚úÖ **Final Checklist for IPSI Deployment**

### **Before You Hand Over:**

**Code Features:**
- [ ] DELETE endpoint implemented
- [ ] EXPORT endpoint implemented
- [ ] Auto-cleanup script created
- [ ] Opt-out mechanism added
- [ ] Sensitive data validation
- [ ] Audit logging
- [ ] Clean logging (no PII)

**Documentation:**
- [ ] Data retention policy document
- [ ] GDPR compliance guide
- [ ] Operations manual
- [ ] API documentation
- [ ] Deployment instructions

**Testing:**
- [ ] Test deletion (PostgreSQL + Qdrant)
- [ ] Test export (JSON + CSV)
- [ ] Test cleanup script
- [ ] Test opt-out mechanism
- [ ] Test all endpoints

**Deployment:**
- [ ] Docker image ready
- [ ] Environment variables documented
- [ ] Cron job configured
- [ ] Monitoring set up
- [ ] Security audit passed

---

## üéØ **Bottom Line**

### **To Answer Your Question:**

**"What needs to be fixed in the microservice to avoid GDPR issues once IPSI operates it?"**

### **7 Features Required:**

1. üî¥ **DELETE endpoint** - Right to erasure (2-3h)
2. üü† **EXPORT endpoint** - Right to portability (2-3h)
3. üî¥ **Auto-cleanup** - Storage limitation (3-4h)
4. üü° **Opt-out mechanism** - Right to object (2-3h)
5. ‚úÖ **Clean logging** - Already done!
6. üü° **Audit logging** - Accountability (3-4h)
7. üü† **Sensitive data block** - Article 9 protection (1-2h)

**Total: 15-20 hours of implementation**

### **What's Already Good:**
- ‚úÖ Anonymized IDs (perfect!)
- ‚úÖ Clean logging (no PII)
- ‚úÖ Self-contained service
- ‚úÖ Security measures (JWT, HTTPS ready)

### **What's Missing:**
- ‚ùå Deletion capability
- ‚ùå Export capability
- ‚ùå Automatic data cleanup
- ‚ùå Opt-out mechanism

---

**Want me to implement these features now? I can:**
1. Create the DELETE endpoint
2. Create the EXPORT endpoint
3. Create the cleanup script
4. Add opt-out mechanism
5. Add all GDPR features

**Estimated time: I can implement all 7 features for you!** üöÄ

Let me know if you want me to proceed!





